{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author : Vitor Henrique Mendes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                               \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                       \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                      \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                           \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                   \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Importing Maven Dependencies at Runtime Using Almond Kernel\n",
    "import $ivy.`io.delta:delta-core_2.11:0.4.0`\n",
    "import $ivy.`org.apache.spark:spark-core_2.11:2.4.4`\n",
    "import $ivy.`org.apache.spark:spark-sql_2.11:2.4.4`\n",
    "import $ivy.`org.apache.spark:spark-catalyst_2.11:2.4.4`\n",
    "import $ivy.`log4j:log4j:1.2.17`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.SparkConf\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.SparkSession\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.storage.{StorageLevel => Storage}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.types._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mio.delta.tables.DeltaTable\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.Logger\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.Level\n",
       "\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.storage.{StorageLevel => Storage}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "import io.delta.tables.DeltaTable\n",
    "\n",
    "import org.apache.log4j.Logger\n",
    "import org.apache.log4j.Level\n",
    "\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mappConf\u001b[39m: \u001b[32mSparkConf\u001b[39m = org.apache.spark.SparkConf@42c630dd\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@2fe601d9\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val appConf = new SparkConf().setAll(Array(\n",
    "    (\"spark.driver.memory\",\"1g\"),\n",
    "    (\"spark.executor.memory\",\"2g\"),\n",
    "    (\"spark.executor.cores\",\"4\"),\n",
    "    (\"spark.executor.instances\",\"2\")\n",
    "))\n",
    "// Running on Standalone Mode\n",
    "val spark = SparkSession\n",
    "                .builder\n",
    "                .appName(\"Semantix\")\n",
    "                .master(\"spark://vitor-VirtualBox:7077\")\n",
    "                .config(appConf)\n",
    "                .getOrCreate\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------+\n",
      "|value                                                                                 |\n",
      "+--------------------------------------------------------------------------------------+\n",
      "|199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245|\n",
      "+--------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mrawDF\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mpackage\u001b[39m.\u001b[32mDataFrame\u001b[39m = [value: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rawDF = spark.read.option(\"escape\",\"\\\"\").option(\"multiLine\",\"true\").text(\"data/*.gz\")\n",
    "rawDF.show(1,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mhostRegex\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"([0-9]{1,3})\\\\.([0-9]{1,3})\\\\.([0-9]{1,3})\\\\.([0-9]{1,3})\"\u001b[39m\n",
       "\u001b[36mdf\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [origin: string, origin_type: string ... 5 more fields]\n",
       "\u001b[36mres16_2\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m3461613L\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Parsing and Cleaning\n",
    "val hostRegex : String = \"([0-9]{1,3})\\\\.([0-9]{1,3})\\\\.([0-9]{1,3})\\\\.([0-9]{1,3})\"\n",
    "val df = rawDF\n",
    "            .select(split($\"value\",\" \") as \"items\")\n",
    "            .select(\n",
    "                $\"items\".getItem(0) as \"origin\",\n",
    "                when(regexp_extract($\"items\".getItem(0),hostRegex,1) =!= \"\", \"host\").otherwise(\"url\") as \"origin_type\", \n",
    "                translate($\"items\".getItem(3),\"[\",\"\") as \"timestamp\",\n",
    "                translate(trim($\"items\".getItem(5)),\"\\\"\",\"\") as \"request_type\",\n",
    "                $\"items\".getItem(6) as \"request_destine\",\n",
    "                $\"items\".getItem(8).cast(IntegerType) as \"request_code\",\n",
    "                $\"items\".getItem(9).cast(FloatType) as \"total_bytes\"\n",
    "            )\n",
    "            .persist(Storage.MEMORY_ONLY) // Same as df.cache()\n",
    "df.count() // An action to real cache data into Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+------------+-----------------------------------------------+------------+-----------+\n",
      "|origin              |origin_type|timestamp           |request_type|request_destine                                |request_code|total_bytes|\n",
      "+--------------------+-----------+--------------------+------------+-----------------------------------------------+------------+-----------+\n",
      "|199.72.81.55        |host       |01/Jul/1995:00:00:01|GET         |/history/apollo/                               |200         |6245.0     |\n",
      "|unicomp6.unicomp.net|url        |01/Jul/1995:00:00:06|GET         |/shuttle/countdown/                            |200         |3985.0     |\n",
      "|199.120.110.21      |host       |01/Jul/1995:00:00:09|GET         |/shuttle/missions/sts-73/mission-sts-73.html   |200         |4085.0     |\n",
      "|burger.letters.com  |url        |01/Jul/1995:00:00:11|GET         |/shuttle/countdown/liftoff.html                |304         |0.0        |\n",
      "|199.120.110.21      |host       |01/Jul/1995:00:00:11|GET         |/shuttle/missions/sts-73/sts-73-patch-small.gif|200         |4179.0     |\n",
      "|burger.letters.com  |url        |01/Jul/1995:00:00:12|GET         |/images/NASA-logosmall.gif                     |304         |0.0        |\n",
      "|burger.letters.com  |url        |01/Jul/1995:00:00:12|GET         |/shuttle/countdown/video/livevideo.gif         |200         |0.0        |\n",
      "|205.212.115.106     |host       |01/Jul/1995:00:00:12|GET         |/shuttle/countdown/countdown.html              |200         |3985.0     |\n",
      "|d104.aa.net         |url        |01/Jul/1995:00:00:13|GET         |/shuttle/countdown/                            |200         |3985.0     |\n",
      "|129.94.144.152      |host       |01/Jul/1995:00:00:13|GET         |/                                              |200         |7074.0     |\n",
      "+--------------------+-----------+--------------------+------------+-----------------------------------------------+------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10,false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Distinct Hosts are : 137979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdistintHosts\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m137979L\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val distintHosts : Long = df.select($\"host\").distinct().count()\n",
    "println(s\"Number of Distinct Hosts are : ${distintHosts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Requests with code 404 are : 20686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mnotFoundRequests\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m20686L\u001b[39m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val notFoundRequests : Long = df.where($\"request_code\" === 404).count()\n",
    "println(s\"Number of Requests with code 404 are : ${notFoundRequests}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+----+\n",
      "|origin                     |qtde|\n",
      "+---------------------------+----+\n",
      "|hoohoo.ncsa.uiuc.edu       |251 |\n",
      "|piweba3y.prodigy.com       |157 |\n",
      "|jbiagioni.npt.nuwc.navy.mil|132 |\n",
      "|piweba1y.prodigy.com       |114 |\n",
      "|www-d4.proxy.aol.com       |91  |\n",
      "+---------------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df\n",
    " .where($\"origin_type\" === \"url\" && $\"request_code\" === 404)\n",
    " .groupBy(\"origin\")\n",
    " .agg(count(lit(1)) as \"qtde\")\n",
    " .orderBy($\"qtde\".desc)\n",
    " .limit(5)\n",
    " .show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|request_code| timestamp|\n",
      "+------------+----------+\n",
      "|         200|1995-07-01|\n",
      "|         200|1995-07-01|\n",
      "|         200|1995-07-01|\n",
      "|         304|1995-07-01|\n",
      "|         200|1995-07-01|\n",
      "+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mparsedDates\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mpackage\u001b[39m.\u001b[32mDataFrame\u001b[39m = [request_code: int, timestamp: date]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val parsedDates = df.select($\"request_code\",regexp_extract($\"timestamp\",\"\\\\d{2}/\\\\w{1,6}/\\\\d{2,4}\",0) as \"timestamp\")\n",
    "                    .select(\n",
    "                         $\"request_code\",\n",
    "                          when($\"timestamp\".isNotNull && lower($\"timestamp\").contains(\"jul\") , translate($\"timestamp\",\"Jul\",\"07\"))\n",
    "                          .when($\"timestamp\".isNotNull && lower($\"timestamp\").contains(\"aug\"), translate($\"timestamp\",\"Aug\",\"08\"))\n",
    "                          .as(\"timestamp\")\n",
    "                      )\n",
    "                    .select($\"request_code\",to_date($\"timestamp\",\"dd/MM/yyyy\") as \"timestamp\")\n",
    "\n",
    "parsedDates.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+\n",
      "| timestamp|qtde|\n",
      "+----------+----+\n",
      "|1995-07-01| 314|\n",
      "|1995-07-02| 289|\n",
      "|1995-07-03| 473|\n",
      "|1995-07-04| 355|\n",
      "|1995-07-05| 491|\n",
      "|1995-07-06| 630|\n",
      "|1995-07-07| 564|\n",
      "|1995-07-08| 299|\n",
      "|1995-07-09| 341|\n",
      "|1995-07-10| 390|\n",
      "|1995-07-11| 469|\n",
      "|1995-07-12| 459|\n",
      "|1995-07-13| 524|\n",
      "|1995-07-14| 408|\n",
      "|1995-07-15| 252|\n",
      "|1995-07-16| 256|\n",
      "|1995-07-17| 403|\n",
      "|1995-07-18| 463|\n",
      "|1995-07-19| 636|\n",
      "|1995-07-20| 427|\n",
      "+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsedDates\n",
    "    .where(\"request_code = 404\")\n",
    "    .groupBy(\"timestamp\")\n",
    "    .agg(count(lit(1)) as \"qtde\")\n",
    "    .orderBy($\"timestamp\".asc)\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "| total_in_bytes|\n",
      "+---------------+\n",
      "|6.5143741103E10|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg(\n",
    "    sum($\"total_bytes\") as \"total_in_bytes\"\n",
    ").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
